{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Expolortary Data Analysis\"\n",
    "subtitle: \"(EDA)\"\n",
    "author: \"Asad Raza Virk\"\n",
    "date: \"2024.09.18\"\n",
    "format: \n",
    "  pdf:\n",
    "    toc: true\n",
    "    toc-depth: 2\n",
    "    number-sections: true\n",
    "    fig-width: 6\n",
    "    fig-height: 4\n",
    "    fig-caption: true\n",
    "    header-includes:\n",
    "      - \\usepackage{caption}\n",
    "      - \\captionsetup{font=small,labelfont=bf}\n",
    "      - \\usepackage{fancyhdr}\n",
    "      - \\pagestyle{fancy}\n",
    "      - \\fancyhead[L]{Expolortary Data Analysis}\n",
    "      - \\fancyhead[R]{\\thepage}\n",
    "      - |\n",
    "        \\fancyfoot[C]{\n",
    "          Prepared by Asad Raza Virk | Twitter: @virkat | GitHub: {https://github.com/virkat}\n",
    "        }\n",
    "      - \\usepackage{booktabs}\n",
    "      - \\usepackage{graphicx}\n",
    "      - \\usepackage{hyperref}\n",
    "    geometry: \"left=1in, right=1in, top=1in, bottom=1in\"\n",
    "    fontfamily: times\n",
    "    fontsize: 11pt\n",
    "    linestretch: 1.5\n",
    "    highlight-style: tango\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 2\n",
    "    number-sections: true\n",
    "    fig-width: 6\n",
    "    fig-height: 4\n",
    "    fig-caption: true\n",
    "    self-contained: true\n",
    "    code-fold: true\n",
    "    include-in-header: |\n",
    "      <meta name=\"author\" content=\"Asad Raza Virk\">\n",
    "      <meta name=\"twitter\" content=\"@virkat\">\n",
    "      <meta name=\"github\" content=\"https://github.com/virkat\">\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage\n",
    "# Elements of Structured Data\n",
    "\n",
    "- Data comes from many sources: sensor measurements, events, text, images, and videos.\n",
    "\n",
    "- The Internet of Things (IoT) is spewing out streams of information. Much of this data is unstructured: images are a collection of pixels, with each pixel containing RGB (red, green, blue) color information.\n",
    "\n",
    "- Texts are sequences of words and non-word characters, often organized by sections, subsections, and so on.\n",
    "\n",
    "- Clickstreams are sequences of actions by a user interacting with an app or a web page.\n",
    "\n",
    "- A major challenge of data science is to harness this torrent of raw data into actionable information.\n",
    "\n",
    "- To apply the statistical concepts , unstructured raw data must be processed and manipulated into a structured form.\n",
    "\n",
    "One of the commonest forms of structured data is a table with rows and columns—as data might emerge from a relational database or be collected for a study\n",
    "\n",
    "## Two basic types of Structured Data\n",
    "\n",
    "1. **Numeric**\n",
    "    - continuous\n",
    "        such as wind speed or time duration\n",
    "    - discrete  \n",
    "        such as the count of the occurrence of an event  \n",
    "2. **Categorical** (takes only fixed set of values)\n",
    "    - **Binary**\n",
    "        Binary data is an important special case of categorical data that takes on only one of two values, such as 0/1, yes/no, or true/false\n",
    "    - **Ordinal**\n",
    "        Ordinal data in which the categories are ordered; an example of this is a numerical rating (1, 2, 3, 4, or 5)\n",
    "\n",
    "For the purposes of data analysis and predictive modeling, the data type is important to help determine the type of visual display, data analysis, or statistical model.\n",
    "\n",
    "Data science software, such as R and Python, uses these data types to improve computational performance. More important, the data type for a variable determines how software will handle computations for that variable.\n",
    "\n",
    "## Key Terms for Data Types\n",
    "\n",
    "1.  **Numeric** Data that are expressed on a numeric scale.\n",
    "    - **Continuous** Data that can take on any value in an interval.        (Synonyms: Interval, float, numeric)\n",
    "    - **Discrete** Data that can take on only integer values, such as counts. (Synonyms: integer, count)\n",
    "2. **Categorical** Data that can take on only a specific set of values     representing a set of possible categories. (Synonyms: enums, enumerated, factors, nominal)\n",
    "    - **Binary** A special case of categorical data with just two categories of values, e.g., 0/1, true/false. \n",
    "        (Synonyms: dichotomous, logical, indicator, boolean)\n",
    "    - **Ordinal** Categorical data that has an explicit ordering. \n",
    "        (Synonym: ordered factor)\n",
    "- **Key Ideas**\n",
    "\n",
    "• Data is typically classified in software by type.\n",
    "\n",
    "• Data types include numeric (continuous, discrete) and categorical (binary, ordinal).\n",
    "\n",
    "• Data typing in software acts as a signal to the software on how to process the data.\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangular and Non-Rectangualr Data\n",
    "\n",
    "## Rectangular Data\n",
    "\n",
    "-   The typical frame of reference for an analysis in data science is a rectangular data object, like a spreadsheet or database table.\n",
    "-   Rectangular data is the general term for a two-dimensional matrix with rows indicating records (cases) and columns indicating features (variables)\n",
    "\n",
    "-   Data frame is the specific format in R and Python.\n",
    "\n",
    "-   The data doesn’t always start in this form: unstructured data (e.g., text) must be processed and manipulated so that it can be represented as a set of features in the rectangular data\n",
    "\n",
    "-   Data in relational databases must be extracted and put into a single table for most data analysis and modeling tasks.\n",
    "\n",
    "### Key Terms for Rectangular Data\n",
    "\n",
    "1. **Data frame**\n",
    "    Rectangular data (like a spreadsheet) is the basic data structure for statistical and machine learning models.\n",
    "2.  **Feature**\n",
    "    A column within a table is commonly referred to as a feature.\n",
    "    Synonyms: attribute, input, predictor, variable\n",
    "3.  **Outcome**\n",
    "    Many data science projects involve predicting an outcome—often a yes/no out‐\n",
    "    come. The features are sometimes used to predict the outcome in an experiment or a study.\n",
    "    Synonyms: dependent variable, response, target, output\n",
    "4.  **Records**\n",
    "    A row within a table is commonly referred to as a record.\n",
    "    Synonyms: case, example, instance, observation, pattern, sample\n",
    "\n",
    "### Data Frames and Indexes\n",
    "Traditional database tables have one or more columns designated as an index, essentially a row number. This can vastly improve the efficiency of certain database queries.\n",
    "\n",
    "In Python, with the pandas library, the basic rectangular data structure is a\n",
    "DataFrame object. By default, an automatic integer index is created for a DataFrame based on the order of the rows.\n",
    "\n",
    "In pandas, it is also possible to set multilevel/hierarchical indexes to improve the efficiency of certain operations.\n",
    "\n",
    "\n",
    "> Terminology Diferences\n",
    "> Terminology for rectangular data can be confusing. Statisticians\n",
    "> and data scientists use different terms for the same thing. For a statistician, predictor variables are used in a model to predict a response or dependent variable. For a data scientist, features are used to predict a target. One synonym is particularly confusing: computer scientists will use the term sample for a single row; a sample to a statistician means a collection of rows.\n",
    "\n",
    "## Non-Rectangular Data Structures\n",
    "\n",
    "There are other data structures besides rectangular data.\n",
    "\n",
    "- **Time series data** records successive   measurements of the same variable. It is the raw material for statistical forecasting methods, and it is also a key component of the data produced by devices—the Internet of Things.\n",
    "\n",
    "- **Spatial data** structures, which are used in mapping and location analytics, are more complex and varied than rectangular data structures. In the object representation, the focus of the data is an object (e.g., a house) and its spatial coordinates. The field view, by contrast, focuses on small units of space and the value of a relevant metric (pixel brightness, for example).\n",
    "\n",
    "- **Graph (or network) data** structures are used to represent physical, social, and abstract relationships. For example, a graph of a social network, such as Facebook or LinkedIn, may represent connections between people on the network. Distribution hubs connected by roads are an example of a physical network. Graph structures are useful for certain types of problems, such as network optimization and recommender systems.\n",
    "\n",
    "    > Graphs in Statistics\n",
    "    > In computer science and information technology, the term graph\n",
    "    > typically refers to a depiction of the connections among entities,\n",
    "    > and to the underlying data structure. In statistics, graph is used to\n",
    "    > refer to a variety of plots and visualizations, not just of connections\n",
    "    > among entities, and the term applies only to the visualization, not\n",
    "    > to the data structure.\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Location of Data\n",
    "- Variables with measured or count data might have thousands of distinct values.\n",
    "- A basic step in exploring your data is getting a “typical value” for each feature (variable): **an estimate of where most of the data is located** (i.e., its central tendency).\n",
    "\n",
    "## Key Terms for Estimates of Location\n",
    "- **Mean**\n",
    "    - The sum of all values divided by the number of values.\n",
    "        - Synonym\n",
    "            - average\n",
    "- **Weighted mean**\n",
    "    - The sum of all values times a weight divided by the \n",
    "    sum of the weights.\n",
    "        - Synonym\n",
    "            - weighted average\n",
    "- **Median**\n",
    "    - The value such that one-half of the data lies above and below.\n",
    "        - Synonym\n",
    "            - 50th percentile\n",
    "- **Percentile**\n",
    "    - The value such that P percent of the data lies below.\n",
    "        - Synonym\n",
    "            - quantile\n",
    "- **Weighted median**\n",
    "    - The value such that one-half of the sum of the weight\n",
    "- **Trimmed mean**\n",
    "    - The average of all values after dropping a fixed number of extreme values.\n",
    "        - Synonym\n",
    "            - truncated mean\n",
    "- **Robust**\n",
    "    - Not sensitive to extreme values.\n",
    "        - Synonym\n",
    "            - resistant\n",
    "- **Outlier**\n",
    "    - A data value that is very different from most of the data.\n",
    "        - Synonym\n",
    "            - extreme value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> **Metrics and Estimates** \n",
    "\n",
    "**Statisticians** often use the term >**estimate** for a value calculated from\n",
    "the data at hand, to draw a distinction between what we see from\n",
    "the data and the theoretical true or exact state of affairs. **Data scientists and >business analysts** are more likely to refer to such a value as a **metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the important Statistical libraries \n",
    "import numpy as np # Fundamental package for numerical computing\n",
    "import pandas as pd # For Data manipulation and analysis\n",
    "from scipy import stats # For Advanced scientific computing and statistical analysis\n",
    "import statsmodels.api as sm # For Statistical modeling and hypothesis testing\n",
    "import seaborn as sns # For Data visualization for understanding statistical distributions\n",
    "import matplotlib.pyplot as plt # For Data visualization for understanding statistical distributions\n",
    "import plotly as plt # For Data visualization for understanding statistical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the US Health Insurance Dataset downlaoded from Kaggle\n",
    "df = pd.read_csv ('./data_sets/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Mean**\n",
    "###  Mean\n",
    "- The mean is the sum of all values divided by the number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of Charges is  13270.422265141257\n"
     ]
    }
   ],
   "source": [
    "# Mean with pandas library\n",
    "print (\"The Mean of Charges is \", df['charges'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mean](01_00_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimmed Mean\n",
    "- A variation of the mean which calculate the mean by dropping a fixed number of sorted values at each end and then taking an average of the remaining values\n",
    "- A trimmed mean eliminates the influence of extreme values\n",
    "- The trimmed mean is a robust measure of central tendency, as it is less affected by outliers than the mean\n",
    "- The trimmed mean is calculated by first sorting the data in ascending order, then dropping a fixed number\n",
    "- For example, in international diving the top score and bottom score from five judges are dropped, and the final score is the average of the scores from the three remaining judges. This makes it difficult for a single judge to manipulate the score, perhaps to favor their country’s\n",
    "contestant.\n",
    "- Trimmed means are widely used, and in many cases are preferable to using the ordinary mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Mean charges: 11076.019520008396\n"
     ]
    }
   ],
   "source": [
    "# import the library for trim mean\n",
    "from scipy.stats import trim_mean\n",
    "# Calculate the trimmed mean, trimming 10% from each end\n",
    "trimmed_mean_charges = trim_mean(df['charges'], proportiontocut=0.1)\n",
    "print(\"Trimmed Mean charges:\", trimmed_mean_charges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Trimmed Mean](01_00_trimmed_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and Trimmed Mean \n",
    "(Mean = Red, Trimmed Mean = Greed)\n",
    "![Mean and Trimmed Mean](01_00_mean_and_trimmed_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outliers**\n",
    "- outliers (extreme cases) could skew the results\n",
    "- An outlier is any value that is very distant from the other values in a data set\n",
    "- The exact definition of an outlier is somewhat subjective\n",
    "- Outliers can be either high or low values\n",
    "- Being an outlier in itself does not make a data value invalid or erroneous\n",
    "- outliers are often the result of data errors such as mixing data of different units (kilometers versus meters) or bad readings from a sensor.\n",
    "- When outliers are the result of bad data, the mean will result in a poor estimate of location, while the median will still be valid\n",
    "- In any case, outliers should be identified and are usually\n",
    "worthy of further investigation.\n",
    "\n",
    "> **Anomaly Detection**\\\n",
    "In contrast to typical data analysis, where outliers are sometimes informative and sometimes a nuisance, in anomaly detection the points of interest are the outliers, and the greater mass of data serves primarily to define the “normal” against which anomalies are measured.\n",
    "\n",
    "\n",
    "The **median** is not the only robust estimate of location. In fact, a **trimmed mean** is widely used to avoid the influence of outliers. For example, trimming the bottom and top 10% (a common choice) of the data will provide protection against outliers in all but the smallest data sets. The **trimmed mean** can be thought of as a compromise between the median and the mean: it is robust to extreme values in the data, but uses more data to calculate the estimate for location.\n",
    "\n",
    "\n",
    "> Weighted mean is available with NumPy. For weighted median, we can use the specialized package wquantiles\n",
    "\n",
    "### **Key Ideas**\n",
    "- The basic metric for location is the mean, but it can be sensitive to extreme values (outlier).\n",
    "- Other metrics (median, trimmed mean) are less sensitive to outliers and unusual distributions and hence are more robust\n",
    "\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Variability\n",
    "\n",
    "##  **Variability**\n",
    "- Location is just one dimension in summarizing a feature\n",
    "- A second dimension, variability, also referred to as dispersion, measures whether the data values are tightly clustered or spread out.\n",
    "- At the heart of statistics lies variability:\n",
    "    - measuring it\n",
    "    - reducing it\n",
    "    - distinguishing random from real variability \n",
    "    - identifying the various sources of real variability\n",
    "    - making decisions in the presence of it\n",
    "- Variability is often measured using the range, interquartile range (IQR), variance, or standard deviation\n",
    "\n",
    "### **Key Terms for Variability Metrics**\n",
    "- **Deviations**\n",
    "    - The difference between the observed values and the estimate of location.\n",
    "        - Synonyms\n",
    "            - errors, residuals\n",
    "- **Variance**\n",
    "    - The sum of squared deviations from the mean divided by n – 1 where n is the number of data values.\n",
    "        - Synonym\n",
    "            - mean-squared-error (MSE)\n",
    "\n",
    "    ![Example](04_1_variance.png)\n",
    "\n",
    "- **Standard deviation**\n",
    "    - The square root of the variance.\n",
    "        - Synonyms\n",
    "            - root mean squared error (RMSE) \n",
    "- **Mean absolute deviation**\n",
    "    - The mean of the absolute values of the deviations from the mean.\n",
    "        - Synonyms\n",
    "            - l1-norm, Manhattan norm   \n",
    "\n",
    "    ![Example](04_2_Mean_Absolute_Deviation.png)\n",
    "- **Median absolute deviation from the median**\n",
    "    -   The median of the absolute values of the deviations from the median\n",
    "    \n",
    "    ![Example](04_3_mad_from_median.jpg)\n",
    "- **Range**\n",
    "    -   The difference between the largest and the smallest value in a data set.\n",
    "- **Order statistics**\n",
    "    -   Metrics based on the data values sorted from smallest to biggest.\n",
    "        - Synonym\n",
    "            -   ranks\n",
    "- **Percentile**\n",
    "    - The value such that P percent of the values take on this value or less and (100–P) percent take on this value or more.\n",
    "        - Synonym\n",
    "            - quantile\n",
    "- **Interquartile range**\n",
    "    - The difference between the 75th percentile and the 25th percentile.\n",
    "        - Synonym\n",
    "            - IQR\n",
    "\n",
    "## **Standard Deviation and Related Estimates**\n",
    "- The most widely used estimates of variation are based on the differences, or **deviations**, between the estimate of location and the observed data.\n",
    "- For a set of data {1, 4, 4}, the mean is 3 and the median is 4. The deviations from the mean are the differences: 1 – 3 = –2, 4 – 3 = 1, 4 – 3 = 1.\n",
    "- These deviations tell us how dispersed the\n",
    "data is around the central value\n",
    "- One way to measure variability is to estimate a typical value for these deviations.Averaging the deviations themselves would not tell us much—the negative deviations offset the positive ones. In fact, the sum of the deviations from the mean is precisely zero.\n",
    "-  Instead, a simple approach is to take the average of the absolute values of the deviations from the mean. In the preceding example, the absolute value of the deviations is {2 1 1}, and their average is (2 + 1 + 1) / 3 = 1.33. This is known as the **mean absolute deviation** \n",
    "- The best-known estimates of variability are the _**variance**_ and the _**standard deviation**_, which are based on _**squared deviations**_. **The variance is an average of the squared deviations, and the standard deviation is the square root of the variance**\n",
    "- The standard deviation is much easier to interpret than the variance since it is on the same scale as the original data. Still, with its more complicated and less intuitive formula, it might seem peculiar that the standard deviation is preferred in statistics over the mean absolute deviation. It owes its preeminence to statistical theory: mathematically, working with squared values is much more convenient than absolute values,\n",
    "especially for statistical models.\n",
    "\n",
    "\n",
    "> here is always some discussion of why we have n – 1 in the denominator in the variance formula, instead of n, leading into the concept of degreesof freedom. This distinction is not important since n is generally large enough that it won’t make much difference whether you divide by n or n – 1. But in case you are interested, here is the story. It is based on the premise that you want to make estimates about a population, based on a sample.\n",
    "> If you use the intuitive denominator of n in the variance formula, you will underestimate the true value of the variance and the standard deviation in the population. This is referred to as a **biased estimate**. However, if you divide by n – 1 instead of n, the variance becomes an **unbiased estimate.**\n",
    "> To fully explain why using n leads to a biased estimate involves the notion of degrees of freedom, which takes into account the number of constraints in computing an estimate. In this case, there are n – 1 degrees of freedom since there is one constraint: the standard deviation depends on calculating the sample mean. For most problems, data scientists do not need to worry about degrees of freedom.\n",
    "\n",
    "- Neither the variance, the standard deviation, nor the mean absolute deviation is robust to outliers and extreme values\n",
    "- The variance and standard deviation are especially sensitive to outliers since they are based on the squared deviations.\n",
    "- A robust estimate of variability is the **median absolute deviation from the median or MAD**\n",
    "- Like the median, the MAD is not influenced by extreme val‐\n",
    "ues.\n",
    "- It is also possible to compute a trimmed standard deviation analogous to the trimmed mean\n",
    "> The variance, the standard deviation, the mean absolute deviation, and the median absolute deviation from the median are not equivalent estimates, even in the case where the data comes from a normal distribution. In fact, the standard deviation is always greater than the mean absolute deviation, which itself is greater than the median absolute deviation. Sometimes, the median absolute deviation is multiplied by a constant scaling factor to put the MAD on the same scale as the standard deviation in the case of a normal distribution. The commonly used factor of 1.4826 means that 50% of the normal distribution fall within the range ±MAD\n",
    "\n",
    "\n",
    "The purpose of calculating deviations in the values is to understand how each individual value differs from the average (mean) value. This helps in several ways:\n",
    "\n",
    "- **Measure of Variability**: Deviations provide a measure of the spread or variability in the data. Large deviations indicate that the charges are spread out over a wide range, while small deviations suggest that the charges are clustered closely around the mean.\n",
    "\n",
    "- **Identify Outliers:** By examining the deviations, you can identify outliers or unusual data points that are significantly different from the mean.\n",
    "\n",
    "- **Statistical Analysis:** Deviations are a fundamental component in various statistical analyses, such as calculating the variance and standard deviation, which are key measures of data dispersion.\n",
    "\n",
    "- **Data Visualization:** Plotting the deviations can help visualize the distribution of the data, making it easier to identify patterns, trends, and anomalies.\n",
    "\n",
    "In statistical analysis, variance and deviation are closely related concepts that measure the spread or dispersion of a dataset. Here’s how they are related:\n",
    "\n",
    "- Deviation:\n",
    "\n",
    "    - Deviation refers to the difference between each data point and the mean of the dataset.\n",
    "    - Deviations can be positive or negative, depending on whether the data point is above or below the mean.\n",
    "    - The sum of deviations from the mean is always zero, as positive deviations cancel out negative deviations\n",
    "\n",
    "- Variance:\n",
    "\n",
    "    - Variance is a measure of how much the data points in a dataset vary from the mean.\n",
    "    - It is calculated as the average of the squared deviations from the mean.\n",
    "    - Squaring the deviations ensures that all values are positive and gives more weight to larger deviations.\n",
    "    - The variance is always non-negative and is zero if all data points are identical\n",
    "\n",
    "- Relationship:\n",
    "\n",
    "    - Variance is essentially the mean of the squared deviations.\n",
    "    - While deviations provide a measure of individual differences from the mean, variance provides a single value that summarizes the overall dispersion of the dataset.\n",
    "    - Variance is used to calculate the standard deviation, which is the square root of the variance and provides a measure of dispersion in the same units as the original data.\n",
    "    \n",
    "In summary, deviations are the building blocks for calculating variance, and variance provides a comprehensive measure of the spread of the data based on these deviations.\n",
    "\n",
    "This code will output a table with the columns for value, mean, deviation, and variance, and it will also plot the deviations. Adjust the df['charges'] list with your actual data if needed.\n",
    "\n",
    "\n",
    "![Example](01_00_multi_figs.png)\n",
    "\n",
    "The variance is a single value that summarizes the overall dispersion of the dataset. It is not specific to individual data points but rather describes the dataset as a whole. Therefore, when you include the variance in the DataFrame, it is the same for every row because it represents the same overall measure of variability for the entire dataset.\n",
    "\n",
    "If you want to include the variance in the DataFrame, it should be shown as a single value, not repeated for each data point. However, if you want to show the squared deviations (which contribute to the variance), you can include those instead.\n",
    "\n",
    "In statistical analysis, the standard deviation and variance are both measures of the spread or dispersion of a dataset. They are closely related but differ in how they express this dispersion.\n",
    "\n",
    "- **Variance**\n",
    "- Definition: Variance measures the average squared deviations from the mean.\n",
    "- Units: The units of variance are the square of the units of the original data. For example, if the data is in meters, the variance will be in square meters.\n",
    "- Formula: Variance = Σ(xi - μ)^2 / (n - 1), where \n",
    "    - xi is each data point,\n",
    "    - μ is the mean of the dataset,\n",
    "    - n is the number of data points, and\n",
    "    - Σ denotes the sum of the squared deviations.\n",
    "\n",
    "- **Standard Deviation**\n",
    "- Definition: Standard deviation is the square root of the variance. It provides a measure of dispersion in the same units as the original data.\n",
    "\n",
    "- Units: The units of standard deviation are the same as the units of the original data. For example, if the data is in meters, the standard deviation will also be in meters.\n",
    "\n",
    "- **Relationship**\n",
    "Mathematical Relationship: The standard deviation is the square root of the variance.\n",
    "- Interpretation:\n",
    "    - Variance gives a measure of how data points spread out from the mean, but because it uses squared units, it can be less intuitive.\n",
    "    - Standard deviation, being in the same units as the data, is often more interpretable and is commonly used to describe the spread of the data.\n",
    "- Example\n",
    "If you have a dataset, the variance tells you the average of the squared differences from the mean, while the standard deviation tells you how much the data points typically deviate from the mean in the original units of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates Based on Percentile**\n",
    "A different approach to estimating dispersion is based on looking at the spread of the sorted data.Statistics based on sorted (ranked) data are referred to as **order statistics**.\n",
    "- The most basic measure is the range: the difference between the largest and smallest numbers. The minimum and maximum values themselves are useful to know and are helpful in identifying outliers, but the range is extremely sensitive to outliers and not very useful as a general measure of dispersion in the data.\n",
    "- To avoid the sensitivity to outliers, we can look at the range of the data after dropping values from each end Formally, these types of estimates are based on differences between **percentiles**\n",
    "- In a data set, the Pth percentile is a value such that at least P percent of the values take on this value or less and at least (100 – P) percent of the values take on this value or more. For example, to find the 80th percentile, sort the data.\n",
    "Then, starting with the smallest value, proceed 80 percent of the way to the largest value. Note that the median is the same thing as the 50th percentile. The percentile is essentially the same as a quantile, with quantiles indexed by fractions (so the .8 quantile is the same as the 80th percentile).\n",
    "- A common measurement of variability is the difference between the 25th percentile and the 75th percentile, called the interquartile range (or IQR).\n",
    "-  Software can have slightly differing approaches that yield different answers \n",
    "- For very large data sets, calculating exact percentiles can be computationally very expensive since it requires sorting all the data values. Machine learning and statistical software use special algorithms, such as [Zhang-Wang-2007], to get an approximate percentile that can be calculated very quickly and is guaranteed to have a certain accuracy.\n",
    "\n",
    "![Range](01_00_range.png)\n",
    "\n",
    "Order statistics are metrics based on the data values sorted from smallest to largest. They provide insights into the distribution and spread of the data. Here are some common order statistics:\n",
    "\n",
    "- Minimum: The smallest value in the dataset.\n",
    "- Maximum: The largest value in the dataset.\n",
    "- Median: The middle value when the data is sorted. If the dataset has an even number of observations, the median is the average of the two middle values.\n",
    "- Quartiles: Values that divide the dataset into four equal parts.\n",
    "    - First Quartile (Q1): The median of the lower half of the dataset (25th percentile).\n",
    "    - Second Quartile (Q2): The median of the dataset (50th percentile).\n",
    "    - Third Quartile (Q3): The median of the upper half of the dataset (75th percentile).\n",
    "- Percentiles: Values that divide the dataset into 100 equal parts. For example, the 90th percentile is the value below which 90% of the data falls.\n",
    "\n",
    "![Percentile](01_00_order_stat.png)\n",
    "\n",
    "\n",
    "\n",
    "![IQR](01_00_order_stat.png)\n",
    "\n",
    "\n",
    "### **Key Ideas**\n",
    "• Variance and standard deviation are the most widespread and routinely reported statistics of variability.\n",
    "\n",
    "• Both are sensitive to outliers.\n",
    "\n",
    "• More robust metrics include mean absolute deviation, median absolute deviation from the median, and percentiles (quantiles).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
